{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "diagnostic-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-representation",
   "metadata": {},
   "source": [
    "# Convert\n",
    "> The Jupyter Notebooks need to be turned into either Markdown or HTML documents to be compatible with the Medium API. Quite good tools to do just this already exists such as Jupyter's `nbconvert` so we are going to use just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "overhead-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ethical-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from nbconvert import MarkdownExporter, FilenameExtension\n",
    "from nbconvert.writers import FilesWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-relay",
   "metadata": {},
   "source": [
    "## Jupyter nbconvert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-lying",
   "metadata": {},
   "source": [
    "Jupyter's nbconvert is a well established tool created and maintained by the core jupyter developers. There is no need to reinvent the wheel, hence we will be using `nbconvert`'s python API to convert Jupyter Notebook to Markdown documents. You can read more about `nbconvert`'s function in the [official documentation](https://nbconvert.readthedocs.io/en/latest/nbconvert_library.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-polls",
   "metadata": {},
   "source": [
    "We will be using `Exporter`, namely the `MarkdownExporter` which can read a python notebook and extract the main body (text) and resources (images, etc). Let's first see the basics of how it works and then make a thin wrapper function around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "departmental-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MarkdownExporter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oriental-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "body, resources = m.from_filename('../samples/test-notebook.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-sector",
   "metadata": {},
   "source": [
    "All notebook exporters return a tuple containing the body and the resources of the document, for instance the matplotlib image from our test notebook was stored as `output_4_1.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minus-expense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['output_13_0.png', 'output_15_0.png', 'output_17_0.png', 'output_17_1.png'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resources['outputs'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-silver",
   "metadata": {},
   "source": [
    "Also it is important to know that so far, the notebook markdown representation only exists as a python object and no files have been written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "familiar-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb2md_draft(notebook:str):\n",
    "    \"\"\"\n",
    "    Paper thin wrapper around nbconvert.MarkdownExporter. This function takes the path to a jupyter\n",
    "    notebook and passes it to `MarkdownExporter().from_filename` which returns the body and resources\n",
    "    of the document\n",
    "    \"\"\"\n",
    "    m = MarkdownExporter()\n",
    "    body, resources = m.from_filename(notebook)\n",
    "    return body, resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-overview",
   "metadata": {},
   "source": [
    "This is a very basic notebook-to-markdown converter that is greatly improved and features are added to it with preprocessors further down in this module, hence this `nb2md()` function is not the one that will be exported and is hence marked as draft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "banner-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, r = nb2md_draft('../samples/test-notebook.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-fraud",
   "metadata": {},
   "source": [
    "## Setting up a module logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "crude-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import logging\n",
    "# for assert statements\n",
    "from io import StringIO\n",
    "# create stream for asserts\n",
    "log_stream = StringIO()\n",
    "import sys\n",
    "\n",
    "def init_logger(name, level = logging.INFO, log_to_stdout = False):\n",
    "    \"\"\"\n",
    "    stream_to_sdout: if true, prints all logging (otherwise seen as stderr)\n",
    "    \"\"\"\n",
    "    #delete loggger handler if it exists\n",
    "    if len(logging.getLogger(name).handlers) != 0:\n",
    "        logging.getLogger(name).\\\n",
    "        removeHandler(logging.getLogger(name).handlers[0])\n",
    "        logging.getLogger(name).\\\n",
    "        removeHandler(logging.getLogger(name).handlers[0])\n",
    "    \n",
    "    # create logger\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    \n",
    "    # create console handler and set level to debug\n",
    "    ch = logging.StreamHandler() \\\n",
    "        if not log_to_stdout else logging.StreamHandler(sys.stdout)\n",
    "    ch.setLevel(level)\n",
    "    \n",
    "    # assert/test handlers\n",
    "    assertch = logging.StreamHandler(log_stream)\n",
    "    assertch.setLevel(level)\n",
    "\n",
    "    # create formatter\n",
    "    formatter = logging.Formatter('%(name)s:%(levelname)s - %(message)s')\n",
    "\n",
    "    # add formatter to ch\n",
    "    ch.setFormatter(formatter)\n",
    "\n",
    "    # add ch to logger\n",
    "    logger.addHandler(ch)\n",
    "    logger.addHandler(assertch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "empty-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_logger('converter', logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "under-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:DEBUG - debug message\n",
      "converter:INFO - info message\n",
      "converter:WARNING - warn message\n",
      "converter:ERROR - error message\n",
      "converter:CRITICAL - critical message\n"
     ]
    }
   ],
   "source": [
    "# 'application' code\n",
    "logger = logging.getLogger('converter')\n",
    "logger.debug('debug message')\n",
    "logger.info('info message')\n",
    "logger.warning('warn message')\n",
    "logger.error('error message')\n",
    "logger.critical('critical message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electric-answer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'debug message\\ninfo message\\nwarn message\\nerror message\\ncritical message\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_stream.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "intense-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert log_stream.getvalue() == '\\\n",
    "debug message\\n\\\n",
    "info message\\n\\\n",
    "warn message\\n\\\n",
    "error message\\n\\\n",
    "critical message\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-slovenia",
   "metadata": {},
   "source": [
    "For the rest of this notebook, I will append the output of `log_stream.getvalue()` to a list `log_list` to test the output of the different operations that I perform as that makes testing clearer (less parsing). For readability I will delete such cells from the rest of this document. Because `.getvalue()` simply concatenates the new stream to the existing stream I will run this little bit of code every time so that I just append the last message to the `log_list` instead of the whole stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acute-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = \"abc\"\n",
    "new = \"abcdef\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "recognized-forwarding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[len(old):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "decent-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list = []\n",
    "log_list.append(log_stream.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "earlier-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert log_list[-1] == '\\\n",
    "debug message\\n\\\n",
    "info message\\n\\\n",
    "warn message\\n\\\n",
    "error message\\n\\\n",
    "critical message\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-limitation",
   "metadata": {},
   "source": [
    "## Writing Notebook to file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-sound",
   "metadata": {},
   "source": [
    "We use the `FilesWriter` object to write the resulting markdown file onto our laptop's storage. We can precise the `build_directory` attribute ([see more Writer options](https://nbconvert.readthedocs.io/en/latest/config_options.html#writer-options)) to indicate where we would like to store our Notebook and the auxiliary files (images, etc). The FilesWriter is \"aggresive\", meaning it will overwrite whatever files exists if there is a directory or filename clash. Lastly, it is also possible to write a custom Writer such as `MediumWriter` that renders the document and then uploads it to Medium but because I am learning I'd rather see every step in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chubby-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FilesWriter(build_directory = 'Rendered/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-mattress",
   "metadata": {},
   "source": [
    "Conveniently, the `write()` method of `FilesWriter` returns the output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "coupled-graph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rendered/test-notebook.md'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(output = body, \n",
    "        resources = resources,\n",
    "        notebook_name = 'test-notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-evening",
   "metadata": {},
   "source": [
    "### Simple writing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "finished-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "def WriteMarkdown(body, resources, dir_path = None, filename = None):\n",
    "    \"\"\"\n",
    "    body & resources are the output of any Jupyter nbconvert `Exporter`.\n",
    "    dir_path should be a relative path with respect to the current working directory. \n",
    "    If dir_path is not passed, the output document and its auxiliary files will be written\n",
    "    to the same location than the input jupyter notebook\n",
    "    filename should be the output document's name\n",
    "    \n",
    "    This function returns the location of the newly written file\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger('converter')\n",
    "    if dir_path is None: \n",
    "        dir_path = os.path.join(resources['metadata']['path'], resources['metadata']['name'])\n",
    "    markdown_location = FilesWriter(build_directory = '' if dir_path is None else dir_path) \\\n",
    "    .write(\n",
    "        output = body,\n",
    "        resources = resources,\n",
    "        notebook_name = filename\n",
    "    )\n",
    "    logger.info(f\"Markdown document written to {markdown_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-canon",
   "metadata": {},
   "source": [
    "#### Example 1 - Write to Jupyter's Notebook directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "offensive-kuwait",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:INFO - Markdown document written to ../samples/test-notebook/test-notebook.md\n"
     ]
    }
   ],
   "source": [
    "WriteMarkdown(body, resources, filename = 'test-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "editorial-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "outstanding-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert log_list[-1] == 'Markdown document written to ../samples/test-notebook/test-notebook.md\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-gabriel",
   "metadata": {},
   "source": [
    "#### Example 2 - Write to new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "greenhouse-electron",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:INFO - Markdown document written to Docs/test-notebook.md\n"
     ]
    }
   ],
   "source": [
    "WriteMarkdown(body, resources, dir_path= 'Docs', filename= 'test-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "manufactured-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "noble-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert log_list[-1] == 'Markdown document written to Docs/test-notebook.md\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-greenhouse",
   "metadata": {},
   "source": [
    "#### Example 3 - Write to directory with subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dirty-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:INFO - Markdown document written to Docs/Attempt1/test-notebook.md\n"
     ]
    }
   ],
   "source": [
    "WriteMarkdown(body, resources, dir_path= 'Docs/Attempt1', filename= 'test-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "annual-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "seventh-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert log_list[-1] == 'Markdown document written to Docs/Attempt1/test-notebook.md\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-romania",
   "metadata": {},
   "source": [
    "#### Example 4 - Write outside the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "union-scotland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:INFO - Markdown document written to ../Docs/test-notebook.md\n"
     ]
    }
   ],
   "source": [
    "WriteMarkdown(body, resources, dir_path= '../Docs', filename= 'test-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "restricted-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "painful-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert log_list[-1] == 'Markdown document written to ../Docs/test-notebook.md\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "computational-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "!rm -rf Docs/ Rendered/ ../Docs/ ../samples/test-notebook/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-shirt",
   "metadata": {},
   "source": [
    "## Handling special tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-accordance",
   "metadata": {},
   "source": [
    "### Hide tags - Remove cell if cell has no output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-patent",
   "metadata": {},
   "source": [
    "We may wish certain markdown or code cells to not be present in the output document. To achieve this we can use `nbconvert`'s [`RegexRemovePreprocessor`](https://nbconvert.readthedocs.io/en/latest/removing_cells.html#removing-cells-using-regular-expressions-on-cell-content). preprocessors such as this one can either be registered to an `Exporter`(see [how](https://nbconvert.readthedocs.io/en/latest/api/exporters.html#nbconvert.exporters.Exporter.register_preprocessor)) or passed as part of a config (see [how](https://nbconvert.readthedocs.io/en/latest/removing_cells.html#removing-pieces-of-cells-using-cell-tags)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "smooth-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbconvert.preprocessors import RegexRemovePreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "direct-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MarkdownExporter()\n",
    "m.register_preprocessor(RegexRemovePreprocessor(patterns = ['^#\\s*hide-cell']), enabled = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-antarctica",
   "metadata": {},
   "source": [
    "__Funnily enough__, the `RegexRemovePreprocessor` [only hides cells that have the tag AND that do no produce an output](https://github.com/jupyter/nbconvert/issues/1091). For example:\n",
    "```python \n",
    "#hide-cell\n",
    "a = 1\n",
    "```\n",
    "would be removed, but:\n",
    "```python \n",
    "#hide-cell\n",
    "a = 1\n",
    "print(a) # or simply a\n",
    "````\n",
    "would _not_ be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-green",
   "metadata": {},
   "source": [
    "### Clear Output - Remove cell's output but keep cell's content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-partition",
   "metadata": {},
   "source": [
    "The standard preprocessors aren't really useful for what I want to do. [`RegexRemovePreprocessors`](https://github.com/jupyter/nbconvert/blob/master/nbconvert/preprocessors/regexremove.py) only remove cells if they have no output in addition to matching the pattern(s) specified. The [`ClearOuputPreprocessor`](https://github.com/jupyter/nbconvert/blob/master/nbconvert/preprocessors/clearoutput.py) removes all outputs from a notebook. Hence I am just going to write a custom preprocessor that is able to hide either a cell's source, a cell's output or the whole cell based on pattern matching performed on a cell's source. After some investigation I realised that best way to achieve this was using [cell tags](https://stackoverflow.com/a/48084050/12821043), though I do not like Jupyter's current tag environment. I do not like them because you have to use the GUI entirely to add tags to a cell, navigating to the the top sidebar, then the **View** section and then the **Cell Toolbar** sub-section and finally click on **Tags** to enable this extra chunky section added to all your cells, even those you may not want to add tag onto. *Hence* I've gone for an implementation that allows for both the use of tags and the of use of text/regex based tagging in the custom preprocessor `HidePreprocessor` written below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "outstanding-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from nbconvert.preprocessors import Preprocessor, TagRemovePreprocessor\n",
    "from traitlets import List, Unicode, Set\n",
    "import re\n",
    "\n",
    "class HidePreprocessor(Preprocessor):\n",
    "    \"\"\"\n",
    "    Preprocessor that hides cell's body and only keeps the output based on regex matching\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mode:str):\n",
    "        self.mode = mode\n",
    "        if mode not in ('source', 'output', 'cell'): \n",
    "            raise Exception(f\"Mode {mode} not supported\")\n",
    "        self.pattern = f'^#\\s*%\\s*hide-{mode}'\n",
    "        self.logger = logging.getLogger('converter')\n",
    "    \n",
    "    def preprocess_cell(self, cell, resources, cell_index):\n",
    "        \"\"\"\n",
    "        Preprocessing to apply to each cell.\n",
    "        \"\"\"\n",
    "        \n",
    "        cell, resources = self.hide_(cell, resources, cell_index)\n",
    "        \n",
    "        return cell, resources\n",
    "    \n",
    "    def hide_(self, cell, resources, cell_index):\n",
    "        \n",
    "        mode = self.mode\n",
    "        has_keyword = re.search(self.pattern, cell.source)\n",
    "        # gist handling\n",
    "        if has_keyword:\n",
    "            self.logger.info(f\"Found a hide-{mode} tag in cell #{cell_index}.\")\n",
    "            cell.metadata.tags = [f'hide-{mode}']\n",
    "            # next line only really applies to hide output but good to have it\n",
    "            cell.source = ''.join(cell.source.split('\\n')[1:])\n",
    "            \n",
    "        return cell, resources\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-drunk",
   "metadata": {},
   "source": [
    "`nbconvert` uses [`traitlets`](https://github.com/ipython/traitlets) where I would normally expect an `__init__()` method. Luckily it is quite intuitive to work with traitlets but I do not grasp the pros and cons of using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caroline-animation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nbconvert.preprocessors.tagremove.TagRemovePreprocessor at 0x1044e9220>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MarkdownExporter()\n",
    "m.register_preprocessor(HidePreprocessor(mode = 'source'), enabled = True)\n",
    "m.register_preprocessor(HidePreprocessor(mode = 'output'), enabled = True)\n",
    "m.register_preprocessor(HidePreprocessor(mode = 'cell'), enabled = True)\n",
    "m.register_preprocessor(TagRemovePreprocessor(\n",
    "    remove_input_tags = ('hide-source',),\n",
    "    remove_all_outputs_tags = ('hide-output',),\n",
    "    remove_cell_tags = ('hide-cell',),\n",
    "    enabled = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-diary",
   "metadata": {},
   "source": [
    "The file `test-hiding.ipynb` contains 4 cells printing the string 'My name is Jack'. The first one has no tags added. The second one has the `#hide-source` tag which results in only the output string being present in the Markdown document. The third cell has the `#hide-output` tag added to it which results in only the cell source (\"the code\") being present in the Markdown document. The last cell has the `#hide-cell` tag which removes the whole cell (source and output) altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "complimentary-morris",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:INFO - Found a hide-source tag in cell #3.\n",
      "converter:INFO - Found a hide-output tag in cell #1.\n",
      "converter:INFO - Found a hide-cell tag in cell #5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### The output of the next cell is hidden\n",
      "\n",
      "\n",
      "```\n",
      "print('My name is Jack')\n",
      "```\n",
      "\n",
      "### The source of the next cell is hidden\n",
      "\n",
      "    My name is Jack\n",
      "\n",
      "\n",
      "### The entire next cell is hidden\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b, r = m.from_filename('../samples/test-hiding.ipynb')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "greater-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-hollow",
   "metadata": {},
   "source": [
    "Tag are in cells 3, 1 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "medical-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert re.findall('#([0-9])', log_list[-1]) == ['3', '1', '5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-wound",
   "metadata": {},
   "source": [
    "**Above** has been the exploration of how to implement hiding cells sources, cells outputs and entire cells based on text based tags. These will be added in the main `nb2md()` function at the end of this module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-tattoo",
   "metadata": {},
   "source": [
    "### Gister tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-medline",
   "metadata": {},
   "source": [
    "I like syntax highlighting in Medium articles and this is only available (to my knowledge) via GitHub Gists. We will be making our own [preprocessor](https://nbconvert.readthedocs.io/en/latest/nbconvert_library.html#Using-different-preprocessors) to uploads the source code of cells that start with the special tag `# gist`. Creating a POST request to submit a Github Gist is easy enough, here we have simply translated the [GitHub API](https://docs.github.com/en/rest/reference/gists#create-a-gist) to a python request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-museum",
   "metadata": {},
   "source": [
    "The only thing needed to submit GET/POST request via the GitHub API is a github token. In the same way than with the Medium tokens we can have the environment variable declared in our `~/.bashrc` or `~/.zshrc` files. The documentation to create a token can be found [in this page](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "attempted-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "def check_gh_auth():\n",
    "    logger = logging.getLogger('converter')\n",
    "    if not os.getenv('GITHUB_TOKEN'):\n",
    "        logger.warning('Please declare your GITHUB_TOKEN as an environment variable, \\\n",
    "        read more here: https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token')\n",
    "        return False\n",
    "    else:\n",
    "        logger.debug('GITHUB_TOKEN environment variable found.')\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "postal-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from requests import post\n",
    "import json\n",
    "\n",
    "def upload_gist(gistname , gistcontent, description = \"\", public = False):\n",
    "    \"\"\"\n",
    "    description: Description of gist, i.e. some metatext explaining what the gist is about\n",
    "    gistname: name displayed for the gist, this impacts how the file is rendered based\n",
    "    on the extension (e.g. script.py, README.md, script.R, query.sql...)\n",
    "    gistcontent: this maybe the name of a file or just a a string describing a program\n",
    "    public: whether the gist should be public or private \n",
    "    \"\"\"\n",
    "    if os.path.isfile(gistcontent):\n",
    "        gistname = gistcontent if gistname is None else gistname\n",
    "        gistcontent =  open(gistcontent, 'r').read()\n",
    "        \n",
    "    post_req = post(\"https://api.github.com/gists\",\n",
    "                data = json.dumps({\n",
    "                    'description': description, \n",
    "                    'files': {gistname: {'content': gistcontent}},\n",
    "                    'public': public\n",
    "                }),\n",
    "                headers = {\n",
    "                    'Authorization': f\"token {os.getenv('GITHUB_TOKEN')}\",\n",
    "                    \"Accept\": \"application/vnd.github.v3+json\"\n",
    "                }\n",
    "        )\n",
    "    if post_req.ok:\n",
    "        return post_req.ok, post_req.json()['html_url']\n",
    "    else:\n",
    "        raise Exception(f\"There was an error (response {post_req.status_code}),\\\n",
    "        uploading the gist {gistname},\\\n",
    "        reason: {post_req.reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "recent-colleague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'https://gist.github.com/ec79e3b314b24697e46a1fd1ca3e9a4d')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_gist('ghapitest', gistcontent = '../CONTRIBUTING.md', description = \"nb2medium-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-jaguar",
   "metadata": {},
   "source": [
    "I wish to have a gister that acts like a magic function but without being a magic function, instead it's just a set of instruction that are sent to the parser like so:\n",
    "```python\n",
    "# gist description: My python program gistname: script.py public: false upload: source\n",
    "a = 1\n",
    "b = 2\n",
    "c = a*b\n",
    "```\n",
    "where the `public`, `description` and `upload` flags are optional.\n",
    "\n",
    "The `upload` flag exists to enable the user to upload the ouput of a command as a gist too (text file or html table/pandas dataframe). The user can specify what to upload by specifing `upload: source`, `upload: output`, `upload: both`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-translation",
   "metadata": {},
   "source": [
    "### Handling tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "armed-chicken",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b       c\n",
       "0  1  9    hair\n",
       "1  2  0  potato\n",
       "2  3  1   water"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "import pandas as pd\n",
    "\n",
    "# notebook with example dataframe\n",
    "source = json.load(open(\"../samples/test-gist-output-df.ipynb\"))['cells'][0]['outputs'][0]['data']['text/html'] \n",
    "soup = bs4.BeautifulSoup(''.join(source),'lxml')\n",
    "table = soup.find_all('table')\n",
    "df = pd.read_html(str(table), index_col = 0)[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-digest",
   "metadata": {},
   "source": [
    "We may choose to remove the index column when exporting to csv by running `df.to_csv(index = False)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-writer",
   "metadata": {},
   "source": [
    "Now that we know how how to upload a gist to Github and how to recover an html table as a pandas dataframe we can incorporate these method into our own `GisterPreprocessor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "nutritional-acrylic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:DEBUG - GITHUB_TOKEN environment variable found.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import bs4\n",
    "import pandas as pd\n",
    "\n",
    "class GisterPreprocessor(Preprocessor):\n",
    "    \"\"\"\n",
    "    Preprocessor that detects the presence of the #%gist tag in a Jupyter Notebook cell,\n",
    "    uploads the code in that cell as a GitHub gist for the authenticated user and replaces the original cell\n",
    "    for a link to the gist in the resulting markdown file\n",
    "    \"\"\"\n",
    "    \n",
    "    pattern = '^#.*%\\s*gist'\n",
    "    is_auth = check_gh_auth()\n",
    "    logger = logging.getLogger('converter')\n",
    "    \n",
    "    def preprocess_cell(self, cell, resources, cell_index):\n",
    "        \"\"\"\n",
    "        Preprocessing to apply to each cell.\n",
    "        \"\"\"        \n",
    "        self.upload = 'source' # default\n",
    "        \n",
    "        has_keyword = re.search(self.pattern, cell.source)\n",
    "        # gist handling\n",
    "        if has_keyword:\n",
    "            if self.is_auth:\n",
    "                params = self.get_params(cell)\n",
    "                self.logger.debug(f\"Detected gist tag in cell {cell_index}  with arguments: {', '.join(params.keys())}; uploading...\")\n",
    "                \n",
    "                if 'upload' in params.keys(): \n",
    "                    self.upload = params['upload']\n",
    "                    del params['upload'] \n",
    "                \n",
    "                # upload cell source\n",
    "                payload = '\\n'.join(cell.source.split('\\n')[1:])\n",
    "                cell = self.upload_gist_from_cell(cell, cell_index, params, content = payload)\n",
    "                \n",
    "                # upload output if user chose to\n",
    "                if self.upload != 'source':\n",
    "                    cell, tbl_counter = self.handle_output(cell, cell_index, params)\n",
    "                \n",
    "                # Finally change cell_type to markdown to get rid of outputs\n",
    "                # and ensure good formatting of links\n",
    "                cell.cell_type = 'markdown'\n",
    "                \n",
    "            else: self.logger.info(\"Gist not uploaded as GITHUB_TOKEN could not be found.\")\n",
    "        \n",
    "           \n",
    "            \n",
    "        return cell, resources\n",
    "        \n",
    "    \n",
    "    def get_params(self,cell, **kwargs):\n",
    "        keywords = ['description', 'gistname', 'public', 'upload']\n",
    "        params_string = re.search(r\"%\\s*gist\\s*(.*)\", cell.source.split('\\n')[0])\n",
    "        if params_string is None:\n",
    "            raise Exception('Cell was labelled with a #gist tag but no parameters were passed')\n",
    "        else:\n",
    "            params_string = params_string.group(1)\n",
    "        \n",
    "        for keyword in keywords: \n",
    "            params_string = re.sub(f\"{keyword}\\s*:\", f\"\\n{keyword}:\", params_string)\n",
    "\n",
    "        params_string = params_string.split('\\n')[1:]\n",
    "        params_dict = {}\n",
    "        for param in params_string:\n",
    "            param = param.split(':')\n",
    "            # TODO write exception for when param[1] is not passed\n",
    "            params_dict[param[0]] = param[1].strip()\n",
    "            \n",
    "        # raise exception if no gistname was passed\n",
    "        if 'gistname' not in params_dict.keys(): \n",
    "            raise Exception(\"Parameter gistname was not specified.\")\n",
    "\n",
    "        return params_dict \n",
    "    \n",
    "    def upload_gist_from_cell(self, cell, cell_index, params, content, n_output = 0):\n",
    "        \"\"\"\n",
    "        output_number is 0 by default (source) or positive otherwise, if positive\n",
    "        it corresponds to the n_output-th cell's output element\n",
    "        \"\"\"       \n",
    "        ok, gist_url = upload_gist(gistcontent = content, **params)\n",
    "        if ok:\n",
    "            self.logger.info(f\"Gist {params['gistname']} from cell {cell_index} succesfully uploaded!\")\n",
    "            \n",
    "            if n_output == 0: append = False\n",
    "            elif self.upload =='output' and n_output == 1: append = False\n",
    "            elif self.upload == 'output' and n_output > 1: append = True\n",
    "            elif self.upload == 'both': append = True\n",
    "            else: raise Exception(f\"This gist setup was not expected; setup: {params}, upload: {self.upload}\")\n",
    "            if not append:\n",
    "                cell.source = f\"[{gist_url}]({gist_url})\\n\"\n",
    "            else:\n",
    "                cell.source += f\"\\n[{gist_url}]({gist_url})\\n\"\n",
    "        else:\n",
    "            self.logger.error(f\"Couldn't upload gist {params['gistname']} from cell {cell_index}\")\n",
    "            \n",
    "        return cell\n",
    "    \n",
    "    def handle_output(self, cell, cell_index, params):\n",
    "        \"\"\"\n",
    "        The output of a Jupyter cell is a whole mess\n",
    "        \"\"\"\n",
    "    \n",
    "        # gist output handling\n",
    "        # For each output we'll check the format and upload a separate gist\n",
    "        for n_output, output in enumerate(cell.outputs):\n",
    "            \n",
    "            tbl_counter = 0\n",
    "            # pandas tables are rendered as html tables and \n",
    "            # hence can be detected via the <table> tag\n",
    "            # and also the term dataframe\n",
    "            if 'data' in output.keys():\n",
    "                if 'text/html' in output.data.keys():\n",
    "                    html_src = ''.join(output.data['text/html'])\n",
    "                    if re.search('<table.*', html_src) is not None:\n",
    "                        tbl_counter += 1\n",
    "                        self.logger.debug(f\"Found table in cell {cell_index}, uploading...\")\n",
    "                        # (try) turn html table into dataframe\n",
    "                        try:\n",
    "                            soup = bs4.BeautifulSoup(html_src,'lxml')\n",
    "                            table = soup.find_all('table')\n",
    "                            payload = pd.read_html(str(table), index_col = 0)[0].to_csv(index = False)\n",
    "                            params['gistname'] += \".csv\"\n",
    "                        except:\n",
    "                            self.logger.warning('Could not turn table to dataframe, uploading as html file')\n",
    "                            payload = html_src\n",
    "                            params['gistname'] += \".html\"\n",
    "\n",
    "                elif 'text/plain' in output.data.keys():\n",
    "                    self.logger.debug(f\"Uploading output from cell {cell_index} as text file...\")\n",
    "                    # output.data['text/plain'] returns a list so we join in into a string\n",
    "                    # on its way out\n",
    "                    payload = ''.join(output.data['text/plain'])\n",
    "                    params['gistname'] += \".txt\"\n",
    "\n",
    "                \n",
    "            elif 'output_type' in output.keys() and output.output_type == 'stream':\n",
    "                self.logger.debug(f\"Detected printed output in cell {cell_index}, uploading...\")\n",
    "                payload = ''.join(output.text)\n",
    "                params['gistname'] += \".txt\"\n",
    "                \n",
    "            cell = self.upload_gist_from_cell(cell, cell_index, params, payload, n_output + 1)\n",
    "                        \n",
    "        return cell, tbl_counter \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "prescription-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-juice",
   "metadata": {},
   "source": [
    "__Note:__ The output of the *gisted* cell will be removed as the code cell is turned into a markdown cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "welsh-trader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GisterPreprocessor at 0x10f88b5e0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MarkdownExporter()\n",
    "m.register_preprocessor(GisterPreprocessor(), enabled = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "systematic-principal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:DEBUG - Detected gist tag in cell 1  with arguments: description, gistname; uploading...\n",
      "converter:INFO - Gist script.py from cell 1 succesfully uploaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Uploading cells as gists            \n",
      "\n",
      "[https://gist.github.com/9fecb3ad0fb45f39d13f44f6f88b191a](https://gist.github.com/9fecb3ad0fb45f39d13f44f6f88b191a)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b, r = m.from_filename('../samples/test-gist.ipynb')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "generic-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "alien-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert log_list[-1] == \"\\\n",
    "Detected gist tag in cell 1  with arguments: description, gistname; uploading...\\n\\\n",
    "Gist script.py from cell 1 succesfully uploaded!\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cubic-newcastle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:DEBUG - Detected gist tag in cell 0  with arguments: description, gistname, upload; uploading...\n",
      "converter:INFO - Gist pandas.py from cell 0 succesfully uploaded!\n",
      "converter:DEBUG - Found table in cell 0, uploading...\n",
      "converter:INFO - Gist pandas.py.csv from cell 0 succesfully uploaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[https://gist.github.com/2cc69823ad165489bcab0b552aa39daf](https://gist.github.com/2cc69823ad165489bcab0b552aa39daf)\n",
      "\n",
      "[https://gist.github.com/5ef13d2bf695adcbca51a3e28feb88c5](https://gist.github.com/5ef13d2bf695adcbca51a3e28feb88c5)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b, r = m.from_filename('../samples/test-gist-output-df.ipynb')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "rubber-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "tested-terrorism",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:DEBUG - Detected gist tag in cell 1  with arguments: description, gistname, upload; uploading...\n",
      "converter:INFO - Gist script.py from cell 1 succesfully uploaded!\n",
      "converter:DEBUG - Detected printed output in cell 1, uploading...\n",
      "converter:INFO - Gist script.py.txt from cell 1 succesfully uploaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Uploading cells as gists            \n",
      "\n",
      "[https://gist.github.com/26d5e047dfbb821351f6f2f1ecaff915](https://gist.github.com/26d5e047dfbb821351f6f2f1ecaff915)\n",
      "\n",
      "[https://gist.github.com/572914339a6151c64716944b73efe443](https://gist.github.com/572914339a6151c64716944b73efe443)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b, r = m.from_filename('../samples/test-gist-output-print.ipynb')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "posted-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "unauthorized-medicaid",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:DEBUG - Detected gist tag in cell 1  with arguments: description, gistname, upload; uploading...\n",
      "converter:INFO - Gist script.py from cell 1 succesfully uploaded!\n",
      "converter:DEBUG - Detected printed output in cell 1, uploading...\n",
      "converter:INFO - Gist script.py.txt from cell 1 succesfully uploaded!\n",
      "converter:DEBUG - Found table in cell 1, uploading...\n",
      "converter:INFO - Gist script.py.txt.csv from cell 1 succesfully uploaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Uploading cells as gists            \n",
      "\n",
      "[https://gist.github.com/5ab06f2a1a9c47921ac043ad17975aa2](https://gist.github.com/5ab06f2a1a9c47921ac043ad17975aa2)\n",
      "\n",
      "[https://gist.github.com/b23613968dbafa5b1e318de45696858e](https://gist.github.com/b23613968dbafa5b1e318de45696858e)\n",
      "\n",
      "[https://gist.github.com/1f5da1f58fb5213e4de0cf0458a442b6](https://gist.github.com/1f5da1f58fb5213e4de0cf0458a442b6)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b, r = m.from_filename('../samples/test-gist-multi-mode-output.ipynb')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "clear-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "primary-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "!rm -rf ../samples/test-gister.md ../samples/test-notebook.md ../samples/test-dataframe.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "extra-council",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown command \"delete\" for \"gh gist\"\n",
      "\n",
      "Usage:  gh gist [flags]\n",
      "\n",
      "Available commands:\n",
      "  create\n",
      "  edit\n",
      "  list\n",
      "  view\n",
      "unknown command \"delete\" for \"gh gist\"\n",
      "\n",
      "Usage:  gh gist [flags]\n",
      "\n",
      "Available commands:\n",
      "  create\n",
      "  edit\n",
      "  list\n",
      "  view\n",
      "unknown command \"delete\" for \"gh gist\"\n",
      "\n",
      "Usage:  gh gist [flags]\n",
      "\n",
      "Available commands:\n",
      "  create\n",
      "  edit\n",
      "  list\n",
      "  view\n",
      "unknown command \"delete\" for \"gh gist\"\n",
      "\n",
      "Usage:  gh gist [flags]\n",
      "\n",
      "Available commands:\n",
      "  create\n",
      "  edit\n",
      "  list\n",
      "  view\n",
      "unknown command \"delete\" for \"gh gist\"\n",
      "\n",
      "Usage:  gh gist [flags]\n",
      "\n",
      "Available commands:\n",
      "  create\n",
      "  edit\n",
      "  list\n",
      "  view\n",
      "unknown command \"delete\" for \"gh gist\"\n",
      "\n",
      "Usage:  gh gist [flags]\n",
      "\n",
      "Available commands:\n",
      "  create\n",
      "  edit\n",
      "  list\n",
      "  view\n",
      "unknown command \"delete\" for \"gh gist\"\n",
      "\n",
      "Usage:  gh gist [flags]\n",
      "\n",
      "Available commands:\n",
      "  create\n",
      "  edit\n",
      "  list\n",
      "  view\n",
      "unknown command \"delete\" for \"gh gist\"\n",
      "\n",
      "Usage:  gh gist [flags]\n",
      "\n",
      "Available commands:\n",
      "  create\n",
      "  edit\n",
      "  list\n",
      "  view\n",
      "unknown command \"delete\" for \"gh gist\"\n",
      "\n",
      "Usage:  gh gist [flags]\n",
      "\n",
      "Available commands:\n",
      "  create\n",
      "  edit\n",
      "  list\n",
      "  view\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# remove gists\n",
    "!for id in $(gh gist list --limit 100 | awk '/nb2medium-test/ { print $1}');do gh gist delete $id; done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-symphony",
   "metadata": {},
   "source": [
    "### Image preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-academy",
   "metadata": {},
   "source": [
    "As we have noticed before when we use an `nbconvert`'s exporter on a Jupyter notebook it extracts the images from that notebook (e.g. plots) and stores them locally. We now need to take those images, upload them to Medium and replace the image with the image URL. It is very similar to what we have done with code cells.m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-telephone",
   "metadata": {},
   "source": [
    "Notice in the cell below how the cells that containg an image have an entry such at `cell['outputs']...['data']['image/png'`]. We can detect the presence of such file and upload the image to Medium via the python Medium API we have written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "occasional-portrait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'metadata', 'output_type']) \n",
      " dict_keys(['image/png', 'text/plain']) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "demonb = json.load(open('../samples/test-notebook.ipynb'))\n",
    "print(\n",
    "    demonb['cells'][13]['outputs'][0].keys(), '\\n',\n",
    "    demonb['cells'][13]['outputs'][0]['data'].keys(), '\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "verbal-suffering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5CklEQVR4nO3dd3hU55X48e8Z9QISQjBq'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demonb['cells'][13]['outputs'][0]['data']['image/png'][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-earth",
   "metadata": {},
   "source": [
    "I am going to make a bold assumption. I am going to assume that if in a given cell the user outputs an image, the user doesn't want anything else to be outputted (e.g. text, or values). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-hindu",
   "metadata": {},
   "source": [
    "The representation of images in raw Jupyter Notebooks is not actually that of a valid image file, the image is represents with ASCII characters. We need to use `binascii.a2b_base64` to turns the ASCII characters into binary ones which results in a valid image, which can then upload to medium. I figured this out by exploring how they extract images in `nbconvert`'s [`ExtractOutputPreprocessor`](https://github.com/jupyter/nbconvert/blob/42cfece9ed07232c3c440ad0768b6a76f667fe47/nbconvert/preprocessors/extractoutput.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "becoming-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb2medium.mediumapi import post_image\n",
    "from binascii import a2b_base64\n",
    "from random import randint #to generate new cell ids\n",
    "\n",
    "class ImagePreprocessor(Preprocessor):\n",
    "    \"\"\"\n",
    "    Preprocessor that detects the presence of the image in a Jupyter Notebook cell's output,\n",
    "    uploads the image to Medium \n",
    "    \"\"\"\n",
    "    \n",
    "    logger = logging.getLogger('converter')\n",
    "    \n",
    "    def preprocess(self, nb, resources):\n",
    "        \"\"\"\n",
    "        Preprocessing to apply to each cell.\n",
    "        Images can either be in a cell's output as a result of a plot being generated in the code (Scenario 1)\n",
    "        Or they can be passed from a local file or the internet in a Markdown cell's source (Scenario 2)\n",
    "        \"\"\"\n",
    "        \n",
    "        n_items = len(nb['cells'])\n",
    "        n = 0\n",
    "        n_plots = n_local_images = 0\n",
    "        while n < n_items:\n",
    "            cell = nb['cells'][n]\n",
    "            cell, newcell, img_count1 = self.upload_image_from_cell_output(cell, n)\n",
    "            cell, img_count2 = self.upload_local_image_from_md(cell, resources, n)\n",
    "            n_plots += img_count1\n",
    "            n_local_images += img_count2\n",
    "            nb['cells'][n] = cell\n",
    "            if newcell is not None:\n",
    "                n_items+=1\n",
    "                #write next cell\n",
    "                nb['cells'].insert(n+1, newcell)\n",
    "                n+=1 # skip cell we've just created\n",
    "            n+=1\n",
    "        \n",
    "        self.logger.info(f\"Detected {n_plots} plots and {n_local_images} local images in notebook.\")\n",
    "        \n",
    "        return nb, resources\n",
    "    \n",
    "    \n",
    "    def upload_local_image_from_md(self, cell, resources, cell_index):\n",
    "        # Scenario 2\n",
    "        # extract name and path of notebook being processed\n",
    "        name = resources['metadata']['name']\n",
    "        path = resources['metadata']['path']\n",
    "        img_counter = 0\n",
    "        \n",
    "        # regex matches the way of insert images in Markdown (e.g `![](somestring)`)\n",
    "        if cell.cell_type == 'markdown' and re.match('!\\[\\]\\(.*\\)', cell.source):\n",
    "            # figure out if path is local or online, if local upload\n",
    "            # we use a capture group in the regex to directly extract the content \n",
    "            # the image tag\n",
    "            imgs = re.findall('!\\[\\]\\((.*)\\)', cell.source)\n",
    "            for img in imgs:\n",
    "                img_path = os.path.join(path, img)\n",
    "                if os.path.isfile(img_path): # local file\n",
    "                    img_counter += 1\n",
    "                    self.logger.debug(msg = f\"Detected {img_counter} local image(s) in cell {cell_index}, uploading...\")\n",
    "                    upload = post_image(filename = img_path)\n",
    "                    ok, upload = upload.ok, upload.json()\n",
    "                    \n",
    "                    if ok:\n",
    "                        url = upload['data']['url']\n",
    "                        self.logger.debug(msg = f\"Image succesfully uploaded to {url}\")\n",
    "                        cell.source = re.sub(pattern = img,\n",
    "                                         repl = url,\n",
    "                                         string = cell.source)\n",
    "                    else:\n",
    "                        self.logger.error(msg = \"Could not upload image to Medium!\")\n",
    "                    \n",
    "        return cell, img_counter\n",
    "        \n",
    "    def upload_image_from_cell_output(self, cell, cell_index):\n",
    "        # Scenario 1\n",
    "        newcell = None\n",
    "        img_counter = 0\n",
    "        if 'outputs' in cell.keys():\n",
    "            \n",
    "            # Iterate thorugh each output of the cell, if at least 1 image is found \n",
    "            # clear all other content; for each img upload and replace with url\n",
    "            # change cell to markdown (output removed in this operation)\n",
    "            newcell = {'cell_type': 'markdown', 'id': str(randint(1e4, 1e5)), 'metadata':{}}\n",
    "            for output in cell.outputs:\n",
    "                # matplotlib images seem to be already in an ASCII PNG format\n",
    "                # hence we are going with that\n",
    "                if 'data' in output.keys():\n",
    "                    if 'image/png' in output.data.keys():\n",
    "                        img_counter += 1\n",
    "\n",
    "                        self.logger.debug(msg = f\"Detected {img_counter} plot(s) in cell {cell_index}, uploading...\")\n",
    "                        img_bin = a2b_base64(output.data['image/png'])\n",
    "\n",
    "                        img = post_image(img = img_bin)\n",
    "                        ok, img = img.ok, img.json()\n",
    "                        if ok:\n",
    "                            url = img['data']['url']\n",
    "                            self.logger.debug(msg = f\"Image succesfully uploaded to {url}\")\n",
    "                            newcell['source'] = f\"![]({url})\\n\" if img_counter == 1 \\\n",
    "                            else '\\n'.join([newcell['source'], f\"![]({url})\\n\"])\n",
    "                        else:\n",
    "                            self.logger.error(msg = \"Could not upload image to Medium!\")\n",
    "\n",
    "\n",
    "            if img_counter > 0: cell.outputs = []\n",
    "            elif img_counter == 0: newcell = None\n",
    "                \n",
    "        return cell, newcell, img_counter\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "mexican-blade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ImagePreprocessor at 0x10f913dc0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MarkdownExporter()\n",
    "m.register_preprocessor(ImagePreprocessor(), enabled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-joint",
   "metadata": {},
   "source": [
    "As we would expect nothing happens when we have a notebook containing online images in it's markdown cells. Medium can access these directly from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecological-powell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:INFO - Detected 0 plots and 0 local images in notebook.\n"
     ]
    }
   ],
   "source": [
    "b, r = m.from_filename('../samples/test-md-online-image.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "numeric-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-complexity",
   "metadata": {},
   "source": [
    "The previous notebook had no plots and no local images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "opposite-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert re.findall('Detected ([0-9]) plots and ([0-9]) local images', log_list[-1]) == [('0', '0')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-joyce",
   "metadata": {},
   "source": [
    "But! If our preprocessor finds offline images, it will upload them to Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "requested-queue",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:DEBUG - Detected 1 local image(s) in cell 0, uploading...\n",
      "converter:DEBUG - Image succesfully uploaded to https://cdn-images-1.medium.com/proxy/1*xYdnXpwz3wapR0XTS4aP6Q.png\n",
      "converter:INFO - Detected 0 plots and 1 local images in notebook.\n"
     ]
    }
   ],
   "source": [
    "b, r = m.from_filename('../samples/test-md-offline-image.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "double-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-commerce",
   "metadata": {},
   "source": [
    "The prior document had 0 plots and 1 local image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "systematic-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert re.findall('Detected ([0-9]) plots and ([0-9]) local images', log_list[-1]) == [('0', '1')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-racing",
   "metadata": {},
   "source": [
    "And finally, if it detects plots such as those coming out of matplotlib, the plot will be uploaded without ever writing the image to memory 😮. In future implementations, more image types can be handles such as plotly interactive plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-cause",
   "metadata": {},
   "source": [
    "#### Works with `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "raising-syndicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:DEBUG - Detected 1 plot(s) in cell 2, uploading...\n",
      "converter:DEBUG - Image succesfully uploaded to https://cdn-images-1.medium.com/proxy/1*Sr5Vt6FDDMwnWQgU8FV9Rw.png\n",
      "converter:INFO - Detected 1 plots and 0 local images in notebook.\n"
     ]
    }
   ],
   "source": [
    "b, r = m.from_filename('../samples/test-matplotlib.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "serious-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "accepted-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert re.findall('Detected ([0-9]) plots and ([0-9]) local images', log_list[-1]) == [('1', '0')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-serial",
   "metadata": {},
   "source": [
    "#### Works with multiple `matplotlib` images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "grand-fence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:DEBUG - Detected 1 plot(s) in cell 2, uploading...\n",
      "converter:DEBUG - Image succesfully uploaded to https://cdn-images-1.medium.com/proxy/1*Sr5Vt6FDDMwnWQgU8FV9Rw.png\n",
      "converter:DEBUG - Detected 2 plot(s) in cell 2, uploading...\n",
      "converter:DEBUG - Image succesfully uploaded to https://cdn-images-1.medium.com/proxy/1*ptKG19-sFG7x90-eg5VkoQ.png\n",
      "converter:INFO - Detected 2 plots and 0 local images in notebook.\n"
     ]
    }
   ],
   "source": [
    "b, r = m.from_filename('../samples/test-multi-matplotlib.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "industrial-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-console",
   "metadata": {},
   "source": [
    "2 plots and 0 local images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dying-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert re.findall('Detected ([0-9]) plots and ([0-9]) local images', log_list[-1]) == [('2', '0')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-adventure",
   "metadata": {},
   "source": [
    "#### Works with `seaborn` plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "painful-needle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converter:DEBUG - Detected 1 plot(s) in cell 2, uploading...\n",
      "converter:DEBUG - Image succesfully uploaded to https://cdn-images-1.medium.com/proxy/1*V2CUHu4F4A2cN4foNjthFA.png\n",
      "converter:INFO - Detected 1 plots and 0 local images in notebook.\n"
     ]
    }
   ],
   "source": [
    "b, r = m.from_filename('../samples/test-seaborn.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "saving-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "log_list.append(log_stream.getvalue()[len(''.join(log_list)):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-understanding",
   "metadata": {},
   "source": [
    "Only one seaborn plot and 0 local images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ordered-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert re.findall('Detected ([0-9]) plots and ([0-9]) local images', log_list[-1]) == [('1', '0')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-clark",
   "metadata": {},
   "source": [
    "## Wrapping it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-undergraduate",
   "metadata": {},
   "source": [
    "Given all the work we have done making the final function that wraps eveything together is easy! We combine all the tools we have built in this module in the `uploader` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fatal-stereo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_mediumapi.ipynb.\n",
      "Converted 01_convert.ipynb.\n",
      "Converted 02_upload.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
